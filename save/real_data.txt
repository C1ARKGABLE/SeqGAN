We’ve not been here before. Human jobs and careers that were once thought of as safe are being challenged in droves. Robots and AI won’t take over the world, but they will take over your job. As mechanical earth movers have cut human labor needs, so too will digital minds cut the need for human thinkers.

In her article, Humans need not apply: The future of jobs is robot-shaped, Margareta Pagano highlights some of the problems our modern economy is currently facing. Pagano points out that after the 2008 recession, “job growth fueling the recovery is tilted in one direction – towards low-wage industries that pay minimum wages, some with little or no benefits, and many of which are part-time”. These jobs are the most widespread, but are also the most easy to automate. Pagano takes the transportation industry as an example, “the transport industry will be hit the hardest and quickest by driverless cars as it's such a big employer – there are three million car-related jobs in the US and around 70 million across the world”. These jobs can be automated right now, with current technology that exists. Losing transportation jobs will leave millions around the world laid off, not because they’re not qualified, but because they have become a liability for the company.

In his 1930 essay, Economic Possibilities for our Grandchildren, John Maynard Keynes, a mathematician turned economist writes about a future we might soon be living in. Keynes poses that, “In quite a few years – in our own lifetimes I mean – we may be able to perform all the operations of agriculture, mining, and manufacture with a quarter of the human effort to which we have been accustomed”. This has truly been realized today with heavy machinery being so prolific in our modern world, but what would a modern Keynes say? Given all the technologic advancements, he would draw parallels between the mechanical replacing human muscles and the digital replacing human brains. Keynes writes in his article that these changes will come “with dread of the readjustment of the habits and instincts of the ordinary man, bred into him for countless generations, which he may be asked to discard within a few decades”. The ordinary women and men of today are bred with the habits to strive for monetary stability, in the future, maybe we can strive for individual betterment.

In his 2018 paper, WILL ROBOTS AUTOMATE YOUR JOB AWAY? FULL EMPLOYMENT, BASIC INCOME, AND ECONOMIC DEMOCRACY,  Ewan McGaughey describes how human law can prevent the loss of all human run jobs. McGaughey dives deep into three possible outcomes and their respective solutions for solving the impending crisis. Some are simple and have been done before, like the Full Employment of Post WWII UK when “42% of UK jobs were redundant but social policy maintained full employment, and it can be done again”. Others are radical, like Basic Income or universal social security. These solutions all come with up and downsides, discussed in this paper.

In his 2016 book, Trekonomics, French economist Manu Saadia dives deep into the economics of Star Trek. The science fiction series “is an economic utopia” according to Saadia, and it solves what “British economist John Maynard Keynes called 'the economic problem’”. By removing current economic conditions by providing an abundance of resources, currency, labor, crime, poverty, and ill health are removed from the universe. 


There are bright spots on the jobs front – new figures out last week showed the number of unemployed people fell to a six year low, those claiming Jobseeker's Allowance are down to a million while the number of self-employed shot up. Sounds good?

Think again. The job growth fuelling the recovery is tilted in one direction – towards low-wage industries that pay minimum wages, some with little or no benefits, and many of which are part-time. Many of the former middle-class jobs have gone forever – relics of yesterday's economy.

If you want to see why this is going to get worse, watch a terrifying new video out last week by CGP Grey, a YouTube poster who publishes educational films, entitled Humans Need Not Apply. The film has only been up for a few days yet there have been more than one million views: no surprise there.

Grey predicts that there are hundreds of millions more jobs yet to be taken over by the "bots" – the new generation of robots. Just as mechanical muscles (ploughs, tractors, diggers, and so on) made human labour less in demand, so the mechanical minds being built will have the same effect on human "brain labour".

The reason? It's economics, sadly. The first generation of computers in the 1980s were expensive and did only simple, mechanical tasks. Now the new Baxter and Watson "bots" are programmed to do anything from booking aeroplane seats to driving cars, and they are as cheap as chips compared to their human equivalent. Even if the bots take longer than humans to do the job, they are about a hundredth of salary costs. That's why he believes the transport industry will be hit the hardest and quickest by driverless cars as it's such a big employer – there are three million car-related jobs in the US and around 70 million across the world.

A core objective of a learner is to generalize from its experience. Generalization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases.

The computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The bias–variance decomposition is one way to quantify generalization error.

For the best performance in the context of generalization, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has under fitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalization will be poorer.

In addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in polynomial time. There are two kinds of time complexity results. Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time.

Unsupervised learning algorithms take a set of data that contains only inputs, and find structure in the data, like grouping or clustering of data points. The algorithms, therefore, learn from test data that has not been labeled, classified or categorized. Instead of responding to feedback, unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data. A central application of unsupervised learning is in the field of density estimation in statistics, though unsupervised learning encompasses other domains involving summarizing and explaining data features.

Cluster analysis is the assignment of a set of observations into subsets (called clusters) so that observations within the same cluster are similar according to one or more predesignated criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some similarity metric and evaluated, for example, by internal compactness, or the similarity between members of the same cluster, and separation, the difference between clusters. Other methods are based on estimated density and graph connectivity.

Supervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs. The data is known as training data, and consists of a set of training examples. Each training example has one or more inputs and the desired output, also known as a supervisory signal. In the mathematical model, each training example is represented by an array or vector, sometimes called a feature vector, and the training data is represented by a matrix. Through iterative optimization of an objective function, supervised learning algorithms learn a function that can be used to predict the output associated with new inputs. An optimal function will allow the algorithm to correctly determine the output for inputs that were not a part of the training data. An algorithm that improves the accuracy of its outputs or predictions over time is said to have learned to perform that task.

Supervised learning algorithms include classification and regression. Classification algorithms are used when the outputs are restricted to a limited set of values, and regression algorithms are used when the outputs may have any numerical value within a range. Similarity learning is an area of supervised machine learning closely related to regression and classification, but the goal is to learn from examples using a similarity function that measures how similar or related two objects are. It has applications in ranking, recommendation systems, visual identity tracking, face verification, and speaker verification.

In the case of semi-supervised learning algorithms, some of the training examples are missing training labels, but they can nevertheless be used to improve the quality of a model. In weakly supervised learning, the training labels are noisy, limited, or imprecise; however, these labels are often cheaper to obtain, resulting in larger effective training sets.

The debates about basic income and automation are closely linked. For example, Mark Zuckerberg argues that the increase in automation creates a greater need for basic income. Concerns about automation have prompted many in the high-technology industry to argue for basic income as an implication of their business models. U.S. presidential candidate and non-profit founder Andrew Yang has stated that automation caused the loss of 4 million manufacturing jobs in the Midwest and resulted in the election of Donald Trump. The CEO of Tesla, Inc. and SpaceX, Elon Musk, came out in support of basic income and Yang due to automation and AI.

Many technologists believe that automation, among other things, is creating technological unemployment. Journalist Nathan Schneider first highlighted the turn of the "tech elite" to these ideas with an article in Vice magazine which cited Marc Andreessen, Sam Altman, Peter Diamandis and others. Some studies about automation and jobs validate these concerns. In a report to the Congress, the White House estimated that a worker earning less than $20 an hour in 2010 would eventually lose their job to a machine with 83% probability. Even workers earning as much as $40 an hour faced a probability of 31%. With a rising unemployment rate, poor communities would become more impoverished worldwide. Proponents of universal basic income argue that it could solve many world problems like high work stress and could create more opportunities and efficient and effective work. In a study in Dauphin, Manitoba, only 13% of labor decreased from a much higher expected number. In a study in several Indian villages, basic income in the region raised the education rate of young people by 25%.

Besides technological unemployment, some tech-industry experts worry that automation would destabilize the labor market or increase economic inequality. One example is Chris Hughes, co-founder of both Facebook and Economic Security Project. Automation has been happening for hundreds of years and while it has not permanently reduced the employment rate, it has constantly caused employment instability. It displaces workers who spend their lives learning skills that become outmoded and forces them into unskilled labor. Paul Vallée, a Canadian tech-entrepreneur and CEO of Pythian, argues that automation is at least as likely to increase poverty and reduce social mobility as it is to create ever-increasing unemployment rate. At the 2016 North American Basic Income Guarantee Congress in Winnipeg, Vallée examined slavery as a historical example of a period in which capital (African slaves) could do the same things that paid labor (poor whites) could do. He found that slavery did not cause massive unemployment among poor whites, but instead it increased economic inequality and lowered social mobility.

One argument against basic income is that if people have free and unconditional money, they would "get lazy" and not work as much. Critics argue that less work means less tax revenue and hence less money for the state and cities to fund public projects. The degree of any disincentive to employment because of basic income would likely depend on how generous the basic income was.

Some studies have looked at employment levels during the experiments with basic income and negative income tax and similar systems. In the negative income tax-experiments in United States in the 1970s, for example, there was a five percent decline in the hours worked. The work reduction was largest for second earners in two-earner households and weakest for the main earner. The reduction in hours was higher when the benefit was higher. Participants in these experiments knew that the experiment was limited in time.

In the Mincome experiment in rural Dauphin, Manitoba also in the 1970s, there were also slight reductions in hours worked during the experiment. However, the only two groups who worked significantly less were new mothers and teenagers working to support their families. New mothers spent this time with their infant children, and working teenagers put significant additional time into their schooling. Under Mincome, "[t]he reduction of work effort was modest: about one per cent for men, three per cent for wives, and five per cent for unmarried women".

A recent study of the Alaska Permanent Fund Dividend—the largest scale universal basic income program in the United States which has run since 1976—seems to show this belief is untrue. The researchers—Damon Jones from the University of Chicago Harris School of Public Policy and Ioana Marinescu from the University of Pennsylvania School of Public Policy and Practice—maintain that although there is a small decrease in work by recipients due to reasons like those in the Manitoba experiment, there has been a 17 percent increase in part-time jobs. The authors theorize that employment remained steady, because the extra income that let people buy more also increased demand for service jobs. This finding is consistent with the economic data of the time. No effect was seen when it came to jobs in manufacturing, which produce exports. Essentially, the authors argue, macro-economic effects of higher spending supported overall employment. To use an illustrative but hypothetical example, someone who uses the dividend to help with car payments can cut back on hours working as a cashier at a local grocery store. Because more people are spending more, the store must replace the worker who started working less. Meanwhile, distribution of the dividend doesn't affect the international demand for oil and the jobs connected to it. Jones and Marinescu found instead that the larger scale of the program is what allows it to work and not dissuade people out of the work force.

Another study that contradicted such decline in work incentive was a pilot project implemented in 2008 and 2009 in the Namibian village of Omitara. The study found that economic activity actually increased, particularly through the launch of small businesses, and reinforcement of the local market by increasing households' buying power. However, the residents of Omitara were described as suffering "dehumanizing levels of poverty" before the introduction of the pilot, and as such the project's relevance to potential implementations in developed economies is unknown.

James Meade states that a return to full employment can only be achieved if, among other things, workers offer their services at a low enough price that the required wage for unskilled labor would be too low to generate a socially desirable distribution of income. He therefore concludes that a "citizen's income" is necessary to achieve full employment without suffering stagnant or negative growth in wages.

If there is a disincentive to employment because of basic income, the magnitude of such a disincentive may depend on how generous the basic income was. Some campaigners in Switzerland have suggested a level that would be only just liveable, arguing that people would want to supplement it.

Tim Worstall, a writer, blogger and Senior Fellow of the Adam Smith Institute, has argued that traditional welfare schemes create a disincentive to work because such schemes typically cause people to lose benefits at around the same rate that their income rises (a form of welfare trap where the marginal tax rate is 100 percent). He has asserted that this particular disincentive is not a property shared by basic income since the rate of increase is positive at all incomes.

Philippe Van Parijs has argued that basic income at the highest sustainable level is needed to support real freedom, or the freedom to do whatever one "might want to do". By this, Van Parijs means that all people should be free to use the resources of the Earth and the "external assets" people make out of them to do whatever they want. Money is like an access ticket to use those resources, and so to make people equally free to do what they want with world assets, the government should give each individual as many such access tickets as possible—that is, the highest sustainable basic income.

Karl Widerquist and others have proposed a theory of freedom in which basic income is needed to protect the power to refuse work which can be summarized as follows. If the resources necessary to an individual's survival are controlled by another group, that individual has no reasonable choice other than to do whatever the resource-controlling group demands. Before the establishment of governments and landlords, individuals had direct access to the resources they needed to survive. Today, resources necessary for the production of food, shelter and clothing have been privatized in such a way that some have gotten a share and others have not.

Therefore, the argument goes that the owners of those resources owe compensation back to non-owners, sufficient at least for them to purchase the resources or goods necessary to sustain their basic needs. This redistribution must be unconditional because people can consider themselves free only if they are not forced to spend all their time doing the bidding of others simply to provide basic necessities to themselves and their families. Under this argument, personal, political and religious freedom are worth little without the power to say no. In this view, basic income provides an economic freedom which—combined with political freedom, freedom of belief and personal freedom—establish each individual's status as a free person.

Frances Fox Piven argues that an income guarantee would benefit all workers by liberating them from the anxiety that results from the "tyranny of wage slavery" and provide opportunities for people to pursue different occupations and develop untapped potentials for creativity. André Gorz saw basic income as a necessary adaptation to the increasing automation of work, yet basic income also enables workers to overcome alienation in work and life and to increase their amount of leisure time.

These arguments imply that a universal basic income, or UBI, would give people enough freedom to pursue work that is satisfactory or interesting even if that work does not pay enough to sustain their everyday living. One example is that of Nelle Harper Lee, who lived as a single woman in New York City in the 1950s, writing in her free time and supporting herself by working part-time as an airline clerk. She had written several long stories, but achieved no success of note. One Christmas in the late fifties, a generous friend gave her a year's wages as a gift with the note: "You have one year off from your job to write whatever you please. Merry Christmas". A year later, Lee had produced a draft of To Kill a Mockingbird, a novel that subsequently won the Pulitzer Prize. Most proponents of UBI argue that the net creative output from even a small percentage of basic income subscribers would be a significant contributor to human productivity, one that might be lost if these people are not given the opportunity to pursue work that is interesting to them.

It has been argued that proponents of Universal Basic Income choose to ignore that the implementation of such policy would result in a new sense of alienation and meaninglessness for much if the population. UBI differs from the Keynesian concept of 'paying people to dig ditches and then filling them up again', as these people had a job and were doing something whether useful or not, it occupied their time. Under UBI, people are not expected to perform any work which may result in a sense of nihilism.

This issue has been addressed historically in the Moynihan Report in which economist Daniel Moynihan outlined the plight of African Americans. He argued that, without access to jobs and the means to contribute meaningful support to a family, black men would become systematically alienated from their roles as husbands and fathers. This, he argued, would cause increasing rates of divorce, child abandonment, and out-of-wedlock births, as well as other associated antisocial behaviors.

The welfare trap or poverty trap is a proposed problem with means-tested welfare. Recipients of means-tested welfare may be implicitly encouraged to remain on welfare due to economic penalties for transitioning off of welfare. These penalties include loss of welfare and possibly higher tax rates. Opponents claim that this creates a harsh marginal tax for those rising out of poverty. A 2013 Cato Institute study claimed that workers could accumulate more wealth from the welfare system than they could from a minimum wage job in at least nine European countries. In three of them, namely Austria, Croatia and Denmark, the marginal tax rate was nearly 100%.

Proponents of universal basic income claim that it could eliminate welfare traps by removing conditions to receive such an income, but large-scale experiments have not yet produced clear results.

Automation is the technology by which a process or procedure is performed with minimal human assistance. Automation or automatic control is the use of various control systems for operating equipment such as machinery, processes in factories, boilers and heat treating ovens, switching on telephone networks, steering and stabilization of ships, aircraft and other applications and vehicles with minimal or reduced human intervention.

Automation covers applications ranging from a household thermostat controlling a boiler, to a large industrial control system with tens of thousands of input measurements and output control signals. In control complexity, it can range from simple on-off control to multi-variable high-level algorithms.

In the simplest type of an automatic control loop, a controller compares a measured value of a process with a desired set value, and processes the resulting error signal to change some input to the process, in such a way that the process stays at its set point despite disturbances. This closed-loop control is an application of negative feedback to a system. The mathematical basis of control theory was begun in the 18th century and advanced rapidly in the 20th.

Automation has been achieved by various means including mechanical, hydraulic, pneumatic, electrical, electronic devices and computers, usually in combination. Complicated systems, such as modern factories, airplanes and ships typically use all these combined techniques. The benefit of automation includes labor savings, savings in electricity costs, savings in material costs, and improvements to quality, accuracy, and precision.

The World Bank's World Development Report 2019 shows evidence that the new industries and jobs in the technology sector outweigh the economic effects of workers being displaced by automation.

Job losses and downward mobility blamed on Automation has been cited as one of many factors in the resurgence of nationalist and protectionist politics in the US, UK and France, among other countries since 2010s.

The term automation, inspired by the earlier word automatic (coming from automaton), was not widely used before 1947, when Ford established an automation department. It was during this time that industry was rapidly adopting feedback controllers, which were introduced in the 1930s.

In transportation, platooning or flocking is a method for driving a group of vehicles together. It is meant to increase the capacity of roads via an automated highway system.

Platoons decrease the distances between cars or trucks using electronic, and possibly mechanical, coupling. This capability would allow many cars or trucks to accelerate or brake simultaneously. This system also allows for a closer headway between vehicles by eliminating reacting distance needed for human reaction.

Platoon capability might require buying new vehicles, or it may be something that can be retrofitted. Drivers would probably need a special license endorsement on account of the new skills required and the added responsibility when driving in the lead.

Smart cars with artificial intelligence could automatically join and leave platoons. The automated highway system is a proposal for one such system, where cars organize themselves into platoons of 8 to 25.

An automated highway system (AHS), or smart road, is a proposed intelligent transportation system technology designed to provide for driverless cars on specific right-of ways. It is most often recommended as a means of traffic congestion relief, on the grounds that it would drastically reduce following distances and headway, thus allowing a given stretch of road to carry more cars.

The automatic telephone switchboard was introduced in 1892 along with dial telephones. By 1929, 31.9% of the Bell system was automatic. Automatic telephone switching originally used vacuum tube amplifiers and electro-mechanical switches, which consumed a large amount of electricity. Call volume eventually grew so fast that it was feared the telephone system would consume all electricity production, prompting Bell Labs to begin research on the transistor.

The logic performed by telephone switching relays was the inspiration for the digital computer. The first commercially successful glass bottle blowing machine was an automatic model introduced in 1905. The machine, operated by a two-man crew working 12-hour shifts, could produce 17,280 bottles in 24 hours, compared to 2,880 bottles made by a crew of six men and boys working in a shop for a day. The cost of making bottles by machine was 10 to 12 cents per gross compared to $1.80 per gross by the manual glassblowers and helpers.

Sectional electric drives were developed using control theory. Sectional electric drives are used on different sections of a machine where a precise differential must be maintained between the sections. In steel rolling, the metal elongates as it passes through pairs of rollers, which must run at successively faster speeds. In paper making the paper sheet shrinks as it passes around steam heated drying arranged in groups, which must run at successively slower speeds. The first application of a sectional electric drive was on a paper machine in 1919. One of the most important developments in the steel industry during the 20th century was continuous wide strip rolling, developed by Armco in 1928.

Before automation many chemicals were made in batches. In 1930, with the widespread use of instruments and the emerging use of controllers, the founder of Dow Chemical Co. was advocating continuous production.

Self-acting machine tools that displaced hand dexterity so they could be operated by boys and unskilled laborers were developed by James Nasmyth in the 1840s. Machine tools were automated with Numerical control (NC) using punched paper tape in the 1950s. This soon evolved into computerized numerical control (CNC).

Today extensive automation is practiced in practically every type of manufacturing and assembly process. Some of the larger processes include electrical power generation, oil refining, chemicals, steel mills, plastics, cement plants, fertilizer plants, pulp and paper mills, automobile and truck assembly, aircraft production, glass manufacturing, natural gas separation plants, food and beverage processing, canning and bottling and manufacture of various kinds of parts. Robots are especially useful in hazardous applications like automobile spray painting. Robots are also used to assemble electronic circuit boards. Automotive welding is done with robots and automatic welders are used in applications like pipelines.

Research by Carl Benedikt Frey and Michael Osborne of the Oxford Martin School argued that employees engaged in "tasks following well-defined procedures that can easily be performed by sophisticated algorithms" are at risk of displacement, and 47 percent of jobs in the US were at risk. The study, released as a working paper in 2013 and published in 2017, predicted that automation would put low-paid physical occupations most at risk, by surveying a group of colleagues on their opinions. However, according to a study published in McKinsey Quarterly in 2015 the impact of computerization in most cases is not the replacement of employees but automation of portions of the tasks they perform. The methodology of the McKinsey study has been heavily criticized for being transparent and relying on subjective assessments. The methodology of Frey and Osborne has been subjected to criticism, as lacking evidence, historical awareness, or credible methodology. In addition the OECD, found that across the 21 OECD countries, 9% of jobs are automatable.

The Obama White House has pointed out that every 3 months "about 6 percent of jobs in the economy are destroyed by shrinking or closing businesses, while a slightly larger percentage of jobs are added". A recent MIT economics study of automation in the United States from 1990 to 2007 found that there may be a negative impact on employment and wages when robots are introduced to an industry. When one robot is added per one thousand workers, the employment to population ratio decreases between 0.18–0.34 percentages and wages are reduced by 0.25–0.5 percentage points. During the time period studied, the US did not have many robots in the economy which restricts the impact of automation. However, automation is expected to triple (conservative estimate) or quadruple (a generous estimate) leading these numbers to become substantially higher.

Based on a formula by Gilles Saint-Paul, an economist at Toulouse 1 University, the demand for unskilled human capital declines at a slower rate than the demand for skilled human capital increases. In the long run and for society as a whole it has led to cheaper products, lower average work hours, and new industries forming (i.e., robotics industries, computer industries, design industries). These new industries provide many high salary skill-based jobs to the economy. By 2030, between 3 and 14 percent of the global workforce will be forced to switch job categories due to automation eliminating jobs in an entire sector. While the number of jobs lost to automation is often offset by jobs gained from technological advances, the same type of job loss is not the same one replaced and that leading to increasing unemployment in the lower-middle class. This occurs largely in the US and developed countries where technological advances contribute to higher demand for highly skilled labor but demand for middle-wage labor continues to fall. Economists call this trend "income polarization" where unskilled labor wages are driven down and skilled labor is driven up and it is predicted to continue in developed economies.

Unemployment is becoming a problem in the United States due to the exponential growth rate of automation and technology. According to Kim, Kim, and Lee (2017), "A seminal study by Frey and Osborne in 2013 predicted that 47% of the 702 examined occupations in the United States faced a high risk of decreased employment rate within the next 10–25 years as a result of computerization". (p. 1). As many jobs are becoming obsolete, which is causing job displacement, one possible solution would be for the government to assist with a universal basic income (UBI) program. UBI would be a guaranteed, non-taxed income of around $1000 dollars per month, paid to all U.S. citizens over the age of 21. UBI would help those who are displaced, take on jobs that pay less money and still afford to get by. It would also give those that are employed with jobs that are likely to be replaced by automation and technology, extra money to spend on education and training on new demanding employment skills. UBI however, should be seen as a short-term solution because it doesn't fully address the issue of income inequality which will be exacerbated by job displacement.

Technological unemployment is the loss of jobs caused by technological change. It is a key type of structural unemployment.

Technological change typically includes the introduction of labour-saving "mechanical-muscle" machines or more efficient "mechanical-mind" processes (automation). Just as horses employed as prime movers were gradually made obsolete by the automobile, humans' jobs have also been affected throughout modern history. Historical examples include artisan weavers reduced to poverty after the introduction of mechanized looms. During World War II, Alan Turing's Bombe machine compressed and decoded thousands of man-years worth of encrypted data in a matter of hours. A contemporary example of technological unemployment is the displacement of retail cashiers by self-service tills.

That technological change can cause short-term job losses is widely accepted. The view that it can lead to lasting increases in unemployment has long been controversial. Participants in the technological unemployment debates can be broadly divided into optimists and pessimists. Optimists agree that innovation may be disruptive to jobs in the short term, yet hold that various compensation effects ensure there is never a long-term negative impact on jobs, whereas pessimists contend that at least in some circumstances, new technologies can lead to a lasting decline in the total number of workers in employment. The phrase "technological unemployment" was popularized by John Maynard Keynes in the 1930s, who said it was a "only a temporary phase of maladjustment". Yet the issue of machines displacing human labour has been discussed since at least Aristotle's time.

Prior to the 18th century both the elite and common people would generally take the pessimistic view on technological unemployment, at least in cases where the issue arose. Due to generally low unemployment in much of pre-modern history, the topic was rarely a prominent concern. In the 18th century fears over the impact of machinery on jobs intensified with the growth of mass unemployment, especially in Great Britain which was then at the forefront of the Industrial Revolution. Yet some economic thinkers began to argue against these fears, claiming that overall innovation would not have negative effects on jobs. These arguments were formalized in the early 19th century by the classical economists. During the second half of the 19th century, it became increasingly apparent that technological progress was benefiting all sections of society, including the working class. Concerns over the negative impact of innovation diminished. The term "Luddite fallacy" was coined to describe the thinking that innovation would have lasting harmful effects on employment.

The view that technology is unlikely to lead to long term unemployment has been repeatedly challenged by a minority of economists. In the early 1800s these included Ricardo himself. There were dozens of economists warning about technological unemployment during brief intensifications of the debate that spiked in the 1930s and 1960s. Especially in Europe, there were further warnings in the closing two decades of the twentieth century, as commentators noted an enduring rise in unemployment suffered by many industrialized nations since the 1970s. Yet a clear majority of both professional economists and the interested general public held the optimistic view through most of the 20th century.

In the second decade of the 21st century, a number of studies have been released suggesting that technological unemployment may be increasing worldwide. Oxford Professors Carl Benedikt Frey and Michael Osborne, for example, have estimated that 47 percent of U.S. jobs are at risk of automation. However, their findings have frequently been misinterpreted, and on the PBS NewsHours they again made clear that their findings do not necessarily imply future technological unemployment. While many economists and commentators still argue such fears are unfounded, as was widely accepted for most of the previous two centuries, concern over technological unemployment is growing once again. A report in Wired in 2017 quotes knowledgeable people such as economist Gene Sperling and management professor Andrew McAfee on the idea that handling existing and impending job loss to automation is a "significant issue". Regarding a recent claim by Treasury Secretary Steve Mnuchin that automation is not "going to have any kind of big effect on the economy for the next 50 or 100 years", says McAfee, "I don't talk to anyone in the field who believes that." Recent technological innovations have the potential to render humans obsolete with the professional, white-collar, low-skilled, creative fields, and other "mental jobs".

The World Bank's World Development Report 2019 argues that while automation displaces workers, technological innovation creates more new industries and jobs on balance.

All participants in the technological employment debates agree that temporary job losses can result from technological innovation. Similarly, there is no dispute that innovation sometimes has positive effects on workers. Disagreement focuses on whether it is possible for innovation to have a lasting negative impact on overall employment. Levels of persistent unemployment can be quantified empirically, but the causes are subject to debate. Optimists accept short term unemployment may be caused by innovation, yet claim that after a while, compensation effects will always create at least as many jobs as were originally destroyed. While this optimistic view has been continually challenged, it was dominant among mainstream economists for most of the 19th and 20th centuries. For example, labor economists Jacob Mincer and Stephan Danninger develop an empirical study using micro-data from the Panel Study of Income Dynamics, and find that although in the short run, technological progress seems to have unclear effects on aggregate unemployment, it reduces unemployment in the long run. When they include a 5-year lag, however, the evidence supporting a short-run employment effect of technology seems to disappear as well, suggesting that technological unemployment "appears to be a myth".

The concept of structural unemployment, a lasting level of joblessness that does not disappear even at the high point of the business cycle, became popular in the 1960s. For pessimists, technological unemployment is one of the factors driving the wider phenomena of structural unemployment. Since the 1980s, even optimistic economists have increasingly accepted that structural unemployment has indeed risen in advanced economies (ref missing), but they have tended to blame this on globalization and offshoring rather than technological change. Others claim a chief cause of the lasting increase in unemployment has been the reluctance of governments to pursue expansionary policies since the displacement of Keynesianism that occurred in the 1970s and early 80s. In the 21st century, and especially since 2013, pessimists have been arguing with increasing frequency that lasting worldwide technological unemployment is a growing threat.

The first systematic exposition of economic crises, in opposition to the existing theory of economic equilibrium. Prior to that point classical economics had either denied the existence of business cycles, blamed them on external factors, notably war, or only studied the long term. Sismondi found vindication in the Panic of 1825, which was the first unarguably international economic crisis, occurring in peacetime.[citation needed]

Sismondi and his contemporary Robert Owen, who expressed similar but less systematic thoughts in 1817 Report to the Committee of the Association for the Relief of the Manufacturing Poor, both identified the cause of economic cycles as overproduction and underconsumption, caused in particular by wealth inequality. They advocated government intervention and socialism, respectively, as the solution. This work did not generate interest among classical economists, though underconsumption theory developed as a heterodox branch in economics until being systematized in Keynesian economics in the 1930s.

Sismondi's theory of periodic crises was developed into a theory of alternating cycles by Charles Dunoyer, and similar theories, showing signs of influence by Sismondi, were developed by Johann Karl Rodbertus. Periodic crises in capitalism formed the basis of the theory of Karl Marx, who further claimed that these crises were increasing in severity and, on the basis of which, he predicted a communist revolution. Though only passing references in Das Kapital (1867) refer to crises, they were extensively discussed in Marx's posthumously published books, particularly in Theories of Surplus Value. In Progress and Poverty (1879), Henry George focused on land's role in crises – particularly land speculation – and proposed a single tax on land as a solution.

The term "Luddite fallacy" is sometimes used to express the view that those concerned about long term technological unemployment are committing a fallacy, as they fail to account for compensation effects. People who use the term typically expect that technological progress will have no long term impact on employment levels, and eventually will raise wages for all workers, because progress helps to increase the overall wealth of society. The term is based on the early 19th century example of the Luddites. During the 20th century and the first decade of the 21st century, the dominant view among economists has been that belief in long term technological unemployment was indeed a fallacy. More recently, there has been increased support for the view that the benefits of automation are not equally distributed.

There are two underlying premises for why long-term difficulty could develop. The one that has traditionally been deployed is that ascribed to the Luddites (whether or not it is a truly accurate summary of their thinking), which is that there is a finite amount of work available and if machines do that work, there can be no other work left for humans to do. Economists call this the lump of labour fallacy, arguing that in reality no such limitation exists. However, the other premise is that it is possible for long-term difficulty to arise that has nothing to do with any lump of labour. In this view, the amount of work that can exist is infinite, but (1) machines can do most of the "easy" work, (2) the definition of what is "easy" expands as information technology progresses, and (3) the work that lies beyond "easy" (the work that requires more skill, talent, knowledge, and insightful connections between pieces of knowledge) may require greater cognitive faculties than most humans are able to supply, as point 2 continually advances. This latter view is the one supported by many modern advocates of the possibility of long-term, systemic technological unemployment.

In statistics, overfitting is "the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably". An overfitted model is a statistical model that contains more parameters than can be justified by the data. The essence of overfitting is to have unknowingly extracted some of the residual variation (i.e. the noise) as if that variation represented underlying model structure.

Underfitting occurs when a statistical model cannot adequately capture the underlying structure of the data. An underfitted model is a model where some parameters or terms that would appear in a correctly specified model are missing. Underfitting would occur, for example, when fitting a linear model to non-linear data. Such a model will tend to have poor predictive performance.

Overfitting and underfitting can occur in machine learning, in particular. In machine learning, the phenomena are sometimes called "overtraining" and "undertraining".

The possibility of overfitting exists because the criterion used for selecting the model is not the same as the criterion used to judge the suitability of a model. For example, a model might be selected by maximizing its performance on some set of training data, and yet its suitability might be determined by its ability to perform well on unseen data; then overfitting occurs when a model begins to "memorize" training data rather than "learning" to generalize from a trend.

Usually a learning algorithm is trained using some set of "training data": exemplary situations for which the desired output is known. The goal is that the algorithm will also perform well on predicting the output when fed "validation data" that was not encountered during its training.

Overfitting is the use of models or procedures that violate Occam's razor, for example by including more adjustable parameters than are ultimately optimal, or by using a more complicated approach than is ultimately optimal. For an example where there are too many adjustable parameters, consider a dataset where training data for y can be adequately predicted by a linear function of two independent variables. Such a function requires only three parameters (the intercept and two slopes). Replacing this simple function with a new, more complex quadratic function, or with a new, more complex linear function on more than two independent variables, carries a risk: Occam's razor implies that any given complex function is a priori less probable than any given simple function. If the new, more complicated function is selected instead of the simple function, and if there was not a large enough gain in training-data fit to offset the complexity increase, then the new complex function "overfits" the data, and the complex overfitted function will likely perform worse than the simpler function on validation data outside the training dataset, even though the complex function performed as well, or perhaps even better, on the training dataset.

When comparing different types of models, complexity cannot be measured solely by counting how many parameters exist in each model; the expressivity of each parameter must be considered as well. For example, it is nontrivial to directly compare the complexity of a neural net (which can track curvilinear relationships) with m parameters to a regression model with n parameters.

Overfitting is especially likely in cases where learning was performed too long or where training examples are rare, causing the learner to adjust to very specific random features of the training data that have no causal relation to the target function. In this process of overfitting, the performance on the training examples still increases while the performance on unseen data becomes worse.

As a simple example, consider a database of retail purchases that includes the item bought, the purchaser, and the date and time of purchase. It's easy to construct a model that will fit the training set perfectly by using the date and time of purchase to predict the other attributes, but this model will not generalize at all to new data, because those past times will never occur again.

Generally, a learning algorithm is said to overfit relative to a simpler one if it is more accurate in fitting known data (hindsight) but less accurate in predicting new data (foresight). One can intuitively understand overfitting from the fact that information from all past experience can be divided into two groups: information that is relevant for the future, and irrelevant information ("noise"). Everything else being equal, the more difficult a criterion is to predict, the more noise exists in past information that needs to be ignored. The problem is determining which part to ignore. A learning algorithm that can reduce the chance of fitting noise is called "robust."

Underfitting occurs when a statistical model or machine learning algorithm cannot adequately capture the underlying structure of the data. It occurs when the model or algorithm does not fit the data enough. Underfitting occurs if the model or algorithm shows low variance but high bias (to contrast the opposite, overfitting from high variance and low bias). It is often a result of an excessively simple model.

The use of various forms of subsidies has often been accepted as a solution to technological unemployment even by conservatives and by those who are optimistic about the long term effect on jobs. Welfare programmes have historically tended to be more durable once established, compared with other solutions to unemployment such as directly creating jobs with public works. Despite being the first person to create a formal system describing compensation effects, Ramsey McCulloch and most other classical economists advocated government aid for those suffering from technological unemployment, as they understood that market adjustment to new technology was not instantaneous and that those displaced by labour-saving technology would not always be able to immediately obtain alternative employment through their own efforts.

Several commentators have argued that traditional forms of welfare payment may be inadequate as a response to the future challenges posed by technological unemployment, and have suggested a basic income as an alternative. People advocating some form of basic income as a solution to technological unemployment include Martin Ford,  Erik Brynjolfsson, Robert Reich, Andrew Yang, Elon Musk, Zoltan Istvan, and Guy Standing. Reich has gone as far as to say the introduction of a basic income, perhaps implemented as a negative income tax is "almost inevitable", while Standing has said he considers that a basic income is becoming "politically essential". Since late 2015, new basic income pilots have been announced in Finland, the Netherlands, and Canada. Further recent advocacy for basic income has arisen from a number of technology entrepreneurs, the most prominent being Sam Altman, president of Y Combinator.

Skepticism about basic income includes both right and left elements, and proposals for different forms of it have come from all segments of the spectrum. For example, while the best-known proposed forms (with taxation and distribution) are usually thought of as left-leaning ideas that right-leaning people try to defend against, other forms have been proposed even by libertarians, such as von Hayek and Friedman. Republican president Nixon's Family Assistance Plan (FAP) of 1969, which had much in common with basic income, passed in the House but was defeated in the Senate.

One objection to basic income is that it could be a disincentive to work, but evidence from older pilots in India, Africa, and Canada indicates that this does not happen and that a basic income encourages low-level entrepreneurship and more productive, collaborative work. Another objection is that funding it sustainably is a huge challenge. While new revenue-raising ideas have been proposed such as Martin Ford's wage recapture tax, how to fund a generous basic income remains a debated question, and skeptics have dismissed it as utopian. Even from a progressive viewpoint, there are concerns that a basic income set too low may not help the economically vulnerable, especially if financed largely from cuts to other forms of welfare.

To better address both the funding concerns and concerns about government control, one alternative model is that the cost and control would be distributed across the private sector instead of the public sector. Companies across the economy would be required to employ humans, but the job descriptions would be left to private innovation, and individuals would have to compete to be hired and retained. This would be a for-profit sector analog of basic income, that is, a market-based form of basic income. It differs from a job guarantee in that the government is not the employer (rather, companies are) and there is no aspect of having employees who "cannot be fired", a problem that interferes with economic dynamism. The economic salvation in this model is not that every individual is guaranteed a job, but rather just that enough jobs exist that massive unemployment is avoided and employment is no longer solely the privilege of only the very smartest or highly trained 20% of the population. Another option for a market-based form of basic income has been proposed by the Center for Economic and Social Justice (CESJ) as part of "a Just Third Way" (a Third Way with greater justice) through widely distributed power and liberty. Called the Capital Homestead Act, it is reminiscent of James S. Albus's Peoples' Capitalism in that money creation and securities ownership are widely and directly distributed to individuals rather than flowing through, or being concentrated in, centralized or elite mechanisms.

Cloward and Piven's article is focused on forcing the Democratic Party, which in 1966 controlled the presidency and both houses of the United States Congress, to take federal action to help the poor. They stated that full enrollment of those eligible for welfare "would produce bureaucratic disruption in welfare agencies and fiscal disruption in local and state governments" that would: "...deepen existing divisions among elements in the big-city Democratic coalition: the remaining white middle class, the working-class ethnic groups and the growing minority poor. To avoid a further weakening of that historic coalition, a national Democratic administration would be constrained to advance a federal solution to poverty that would override local welfare failures, local class and racial conflicts and local revenue dilemmas."

Basic income can be implemented nationally, regionally or locally. An unconditional income that is sufficient to meet a person's basic needs (at or above the poverty line) is sometimes called a full basic income while if it is less than that amount, it is sometimes called partial. A welfare system with some characteristics similar to those of a basic income is a negative income tax in which the government stipend is gradually reduced with higher labour income. Some welfare systems are sometimes regarded as steps on the way to a basic income, but because they have conditionalities attached they are not basic incomes. If they raise household incomes to specified minima they are called guaranteed minimum income systems. 

Several political discussions are related to the basic income debate. Examples include the debates regarding robotization, artificial intelligence (AI), and the future of work. A key issue in these debates is whether automation and AI will significantly reduce the number of available jobs. Basic income often comes up as a proposal in these discussions.

The idea of a state-run basic Income dates back to the early 16th century, when Sir Thomas More's Utopia depicted a society in which every person receives a guaranteed income. In the late 18th century, English radical Thomas Spence and American revolutionary Thomas Paine both declared their support for a welfare system that guaranteed all citizens a certain income. Nineteenth-century debate on basic income was limited, but during the early part of the 20th century a basic income called a "state bonus" was widely discussed, and in 1946 the United Kingdom implemented unconditional family allowances for the second and subsequent children of every family. In the 1960s and 1970s, the United States and Canada conducted several experiments with negative income taxation, a related welfare system. From the 1980s and onward, the debate in Europe took off more broadly and since then it has expanded to many countries around the world. A few countries have implemented large-scale welfare systems that have some similarities to basic income, such as Bolsa Família in Brazil. From 2008 onward, several experiments with basic income and related systems have taken place.